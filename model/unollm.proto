syntax = "proto3";

package unoLLM;
option go_package = "./model";

message LLMTokenCount {
  int64 total_token = 1;
  int64 prompt_token = 2;
  int64 completion_token = 3;
}

message LLMChatCompletionMessage {
  string role = 1;
  string content = 2;
  optional string tool_call_id = 3;
}


message FunctionCallingParameter {
  string name = 1;
  string type = 2;
  string description = 3;
  repeated string enums = 4;
}

message Function {
  string name = 1;
  string description = 2;
  
  repeated FunctionCallingParameter parameters = 3;
  repeated string requireds = 4;
}

message LLMRequestInfo {
  string llm_api_type = 1;
  string model = 2;
  double temperature = 3;
  double top_p = 4;
  double top_k = 5;
  string url = 6;
  string token = 7;
  map<string, string> metainfo = 8;
  repeated Function functions = 9;
  bool use_function_calling = 10;
}

message LLMRequestSchema {
  repeated LLMChatCompletionMessage messages = 1;
  LLMRequestInfo llm_request_info = 2;
}

message Done {
}

message ToolCall {
  string id = 1;
  string name = 2;
  string arguments = 3;
}

message PartialLLMResponse {
  oneof response {
    string content = 1;
    Done done = 2;
  }
  repeated ToolCall tool_calls = 3;
  optional LLMTokenCount llm_token_count = 4;
}

message LLMResponseSchema {
  LLMChatCompletionMessage message = 1;
  LLMTokenCount llm_token_count = 2;
  repeated ToolCall tool_calls = 3;
}


service UnoLLMv1 {
  rpc BlockingRequestLLM(LLMRequestSchema) returns (LLMResponseSchema) {}
  rpc StreamRequestLLM(LLMRequestSchema) returns (stream PartialLLMResponse) {}
}


message EmbeddingResponse {
  EmbeddingRequestInfo embedding_request_info = 1;
  int32 dimension = 2;
  repeated float vectors = 3;
}

message EmbeddingRequestInfo {
  string llm_api_type = 1;
  string model = 2;
  string url = 3;
  string token = 4;
}

message EmbeddingRequest {
  EmbeddingRequestInfo embedding_request_info = 1;
  string text = 2;
}

service UnoEmbeddingv1 {
  rpc EmbeddingRequestLLM(EmbeddingRequest) returns (EmbeddingResponse) {}
}
